# ğŸ† GPT-OSS ç«èµ›å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“‘ ç›®å½•

- [ç›®æ ‡](#ç›®æ ‡)
- [ğŸ“Œ é‡è¦è¯´æ˜](#-é‡è¦è¯´æ˜)
- [æ ¸å¿ƒæ–‡ä»¶](#æ ¸å¿ƒæ–‡ä»¶)
- [å¿«é€Ÿå¼€å§‹ï¼ˆ5 æ­¥èµ°ï¼‰](#å¿«é€Ÿå¼€å§‹5-æ­¥èµ°)
  - [1ï¸âƒ£ å‡†å¤‡å·¥ä½œç›®å½•ï¼ˆåœ¨å®¿ä¸»æœºï¼‰](#1ï¸âƒ£-å‡†å¤‡å·¥ä½œç›®å½•åœ¨å®¿ä¸»æœº)
  - [2ï¸âƒ£ å¯åŠ¨å¼€å‘å®¹å™¨](#2ï¸âƒ£-å¯åŠ¨å¼€å‘å®¹å™¨)
  - [3ï¸âƒ£ åœ¨å®¹å™¨å†…å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„å¯ç¼–è¾‘ vLLM](#3ï¸âƒ£-åœ¨å®¹å™¨å†…å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„å¯ç¼–è¾‘-vllm)
  - [4ï¸âƒ£ ç¤ºä¾‹: ä¿®æ”¹ä»£ç åå¦‚ä½•recompile](#4ï¸âƒ£-ç¤ºä¾‹-ä¿®æ”¹ä»£ç åå¦‚ä½•recompile)
  - [5ï¸âƒ£ æµ‹è¯•ä¼˜åŒ–æ•ˆæœ](#5ï¸âƒ£-æµ‹è¯•ä¼˜åŒ–æ•ˆæœ)
- [æµ‹è¯•æ¨¡å¼å¯¹æ¯”](#æµ‹è¯•æ¨¡å¼å¯¹æ¯”)
- [ä¸¤ç§æµ‹è¯•æ–¹å¼å¯¹æ¯”](#ä¸¤ç§æµ‹è¯•æ–¹å¼å¯¹æ¯”)
- [è¯„åˆ†æ ‡å‡†](#è¯„åˆ†æ ‡å‡†)
  - [æ€§èƒ½æŒ‡æ ‡ï¼ˆä¸»è¦ï¼‰](#æ€§èƒ½æŒ‡æ ‡ä¸»è¦)
  - [å‡†ç¡®æ€§è¦æ±‚ï¼ˆå¿…é¡»æ»¡è¶³ï¼‰](#å‡†ç¡®æ€§è¦æ±‚å¿…é¡»æ»¡è¶³)
  - [B200 Baseline å¯¹æ¯” ğŸ“Š](#b200-baseline-å¯¹æ¯”-)
- [ä¼˜åŒ–æ–¹å‘å»ºè®®](#ä¼˜åŒ–æ–¹å‘å»ºè®®)
- [å¼€å‘æŠ€å·§](#å¼€å‘æŠ€å·§)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ¨èçš„å·¥ä½œæµç¨‹](#æ¨èçš„å·¥ä½œæµç¨‹)
- [èµ„æºé“¾æ¥](#èµ„æºé“¾æ¥)

---

## ç›®æ ‡

åœ¨ AMD MI355X GPU ä¸Šä¼˜åŒ– vLLM æ¨ç†æ€§èƒ½ï¼ˆGPT-OSS 120B FP4 æ¨¡å‹ï¼‰ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å‡†ç¡®æ€§ã€‚

## ğŸ“Œ é‡è¦è¯´æ˜

æœ¬ç«èµ›çš„æµ‹è¯•åŸºå‡†**å¯¹é½ [InferenceMAX](https://github.com/InferenceMAX/InferenceMAX)** ä»“åº“çš„ AMD MI355X æµ‹è¯•é…ç½®ï¼Œå¹¶ä¼šéšç€ InferenceMAX çš„æ›´æ–°è€ŒåŒæ­¥æ›´æ–°ã€‚

**æ¨¡å‹å·®å¼‚**ï¼š
- **æ¨¡å‹**ï¼š`openai/gpt-oss-120b` (FP4 é‡åŒ–)
- **æ¡†æ¶**ï¼švLLM
- **ç‰¹æ€§**ï¼šä½¿ç”¨ AMD AITER ä¼˜åŒ–çš„ MoE å’Œ attention kernels

## æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/launch_vllm_server.sh` | å¯åŠ¨ vLLM æœåŠ¡å™¨ |
| `amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/gptoss_benchmark` | è¿è¡Œæµ‹è¯•å¹¶æäº¤ç»“æœï¼ˆäºŒè¿›åˆ¶æ–‡ä»¶ï¼‰|
| `amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/all_conc_var.sh` | å¤šå¹¶å‘æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½® |
| `amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/specific_conc_var.sh` | å•é…ç½®æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½® |

## å¿«é€Ÿå¼€å§‹ï¼ˆ5 æ­¥èµ°ï¼‰

### 1ï¸âƒ£ å‡†å¤‡å·¥ä½œç›®å½•ï¼ˆåœ¨å®¿ä¸»æœºï¼‰

```bash
# åœ¨å®¿ä¸»æœºä¸Šåˆ›å»ºå·¥ä½œç›®å½•
mkdir -p ~/competition
cd ~/competition

# å…‹éš† vLLMï¼ˆä½ å°†åœ¨æ­¤åŸºç¡€ä¸Šä¼˜åŒ–ï¼‰
git clone https://github.com/vllm-project/vllm.git

# å…‹éš† AITERï¼ˆAMD GPUç®—å­åº“ï¼‰
git clone --recursive https://github.com/ROCm/aiter.git

# å…‹éš†è„šæœ¬æ–‡ä»¶æ‰€åœ¨ä»“åº“
git clone https://github.com/danielhua23/amdgpu_inferencemax_bounty.git
```

### 2ï¸âƒ£ å¯åŠ¨å¼€å‘å®¹å™¨

**æ³¨æ„**ï¼šè¯·å°† `HF_TOKEN` æ›¿æ¢ä¸ºä½ çš„ Hugging Face Tokenã€‚

```bash
docker run -it \
  --name vllm-dev \
  --ipc=host --shm-size=16g --network=host \
  --privileged --cap-add=CAP_SYS_ADMIN \
  --device=/dev/kfd --device=/dev/dri --device=/dev/mem \
  --cap-add=SYS_PTRACE --security-opt seccomp=unconfined \
  -v /nfsdata/hf_hub_cache-1/:/root/.cache/huggingface \
  -v ~/competition:/workspace \
  -v ~/competition/aiter:/workspace/aiter \
  -v ~/competition/vllm:/workspace/vllm \
  -e HF_TOKEN=your_huggingface_token_here \
  rocm/7.0:rocm7.0_ubuntu_22.04_vllm_0.10.1_instinct_20250927_rc1 \
  /bin/bash
```

**æŒ‚è½½è¯´æ˜**ï¼š
- å®¿ä¸»æœºçš„ `~/competition/*` â†’ å®¹å™¨å†… `/workspace/*`
- åœ¨å®¿ä¸»æœºä¿®æ”¹ä»£ç ï¼Œå®¹å™¨å†…ç«‹å³ç”Ÿæ•ˆï¼ˆåä¹‹äº¦ç„¶ï¼‰
- æµ‹è¯•è„šæœ¬ä½äº `/workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/` ç›®å½•

### 3ï¸âƒ£ åœ¨å®¹å™¨å†…å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„å¯ç¼–è¾‘ vLLM

> refer to https://docs.vllm.ai/en/latest/getting_started/installation/gpu/#build-wheel-from-source

```bash
# å¸è½½å®¹å™¨å†…éƒ¨å·²æœ‰çš„ç›¸å…³åº“
pip uninstall -y aiter vllm

# å®‰è£… AITER
cd /workspace/aiter
python3 setup.py develop
```

éªŒè¯ AITER å®‰è£…ï¼š
```bash
root@mi355:/workspace# pip list | grep aiter
aiter                             0.1.7.post3.dev39+g1f5b378dc        /workspace/aiter
```

å®‰è£… vLLMï¼š
```bash
# è¿›å…¥ vLLM ç›®å½•
cd /workspace/vllm

# å®‰è£…ä¾èµ–
pip install --upgrade pip
pip install -r requirements/rocm.txt

# å®‰è£… vLLMï¼ˆå¯ç¼–è¾‘æ¨¡å¼ï¼‰
pip install --upgrade numba \
    scipy \
    huggingface-hub[cli,hf_transfer] \
    setuptools_scm
pip install "numpy<2"

# Build vLLM for MI GPU
export PYTORCH_ROCM_ARCH="gfx942;gfx950"
python3 setup.py develop

# éªŒè¯
python -c "import vllm; print(vllm.__file__)"
# æœŸæœ›è¾“å‡º: /workspace/vllm/vllm/__init__.py
```

>note: you might meet some error like : ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. transformers 4.56.2 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.1.5 which is incompatible. vllm 0.11.2.dev346+g18523b87f.rocm702 requires numba==0.61.2, but you have numba 0.62.1 which is incompatible. **Just try pip install tranformers -U**

### 4ï¸âƒ£ ç¤ºä¾‹: ä¿®æ”¹ä»£ç åå¦‚ä½•recompile

```bash
# åœ¨å®¹å™¨å†…æˆ–å®¿ä¸»æœºï¼ˆVS Codeï¼‰éƒ½å¯ä»¥ç¼–è¾‘
# ç¤ºä¾‹ï¼šä¼˜åŒ–è°ƒåº¦å™¨
cd /workspace/vllm
vim vllm/engine/llm_engine.py

# å¦‚æœä¿®æ”¹äº† Python ä»£ç ï¼Œæ— éœ€é‡æ–°ç¼–è¯‘ï¼ˆå¯ç¼–è¾‘æ¨¡å¼è‡ªåŠ¨ç”Ÿæ•ˆï¼‰

# å¦‚æœä¿®æ”¹äº† C++/CUDA/HIP æ‰©å±•ï¼Œéœ€è¦é‡æ–°ç¼–è¯‘ï¼š
cd /workspace/vllm
rm -r vllm/*.so
rm -r ./build
pip uninstall -y vllm
python3 setup.py develop
```

### 5ï¸âƒ£ æµ‹è¯•ä¼˜åŒ–æ•ˆæœ

#### æ¨èå·¥ä½œæµç¨‹ â­

```
å¼€å‘é˜¶æ®µï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰
  â†“
1. å•é…ç½®æµ‹è¯•å¹¶æäº¤ï¼ˆæ–¹å¼ 1ï¼‰
   - ç”¨ submit æ¨¡å¼æµ‹è¯•å•ä¸ªé…ç½®ï¼ˆ~15-20åˆ†é’Ÿï¼‰
   - è‡ªåŠ¨æäº¤åˆ° Leaderboardï¼Œå®æ—¶æŸ¥çœ‹æ’å
  â†“
2. å¤šå¹¶å‘æ‰¹é‡æµ‹è¯•å¹¶æäº¤ï¼ˆæ–¹å¼ 2ï¼‰
   - ç”¨ submit æ¨¡å¼æµ‹è¯•æ‰€æœ‰ CONCï¼ˆ~1-2å°æ—¶/ISL-OSLï¼‰
   - è‡ªåŠ¨æäº¤æ‰€æœ‰ç»“æœ
  â†“
å®Œæˆï¼å®æ—¶æŸ¥çœ‹ Leaderboard æ’å ğŸ‰
```

**ä¸ºä»€ä¹ˆæ¨èç›´æ¥ç”¨ submit modeï¼Ÿ**
- âœ… **ä¸€æ­¥åˆ°ä½**ï¼šsubmit = å‡†ç¡®æ€§æµ‹è¯• + æ€§èƒ½æµ‹è¯• + è‡ªåŠ¨æäº¤
- âœ… **å®æ—¶åé¦ˆ**ï¼šç«‹å³çœ‹åˆ° Leaderboard æ’åï¼Œå¿«é€Ÿè¿­ä»£
- âœ… **èŠ‚çœæ—¶é—´**ï¼šæ— éœ€å…ˆ perf å† submitï¼Œç›´æ¥æäº¤å³å¯

---

#### æ–¹å¼ 1: å•é…ç½®æµ‹è¯•ï¼ˆå¿«é€ŸéªŒè¯ï¼‰âš¡

**é€‚ç”¨åœºæ™¯**ï¼šå¼€å‘é˜¶æ®µå¿«é€ŸéªŒè¯å•ä¸ªé…ç½®çš„æ€§èƒ½

```bash
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x

# 1. åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆæ— éœ€æ‰‹åŠ¨ exportï¼‰
source specific_conc_var.sh

# 2. å¯åŠ¨ vLLM æœåŠ¡å™¨ï¼ˆé¦–æ¬¡å¯åŠ¨éœ€è¦ 20+ åˆ†é’Ÿ JIT ç¼–è¯‘ï¼‰
bash launch_vllm_server.sh

# ç­‰å¾…æœåŠ¡å™¨å°±ç»ªåï¼ˆçœ‹åˆ° "Uvicorn running..."ï¼‰ï¼Œè¿è¡Œæµ‹è¯•

# 3. æ¨èï¼šç›´æ¥æµ‹è¯•å¹¶æäº¤ï¼ˆ~15-20åˆ†é’Ÿï¼‰â­
./gptoss_benchmark submit "YourTeam"

# å¯é€‰ï¼šå¦‚æœåªæƒ³å¿«é€ŸéªŒè¯å‡†ç¡®æ€§ï¼ˆ~5-10åˆ†é’Ÿï¼‰
./gptoss_benchmark acc

# å¯é€‰ï¼šå¦‚æœåªæƒ³æµ‹è¯•æ€§èƒ½ä½†ä¸æäº¤ï¼ˆ~15-20åˆ†é’Ÿï¼‰
./gptoss_benchmark perf
```

**ç¯å¢ƒå˜é‡è¯´æ˜**ï¼š`specific_conc_var.sh` ä¼šè®¾ç½®ï¼š
- `MODEL`, `PORT`, `TP`ï¼ˆæœåŠ¡å™¨é…ç½®ï¼‰
- `ISL`, `OSL`, `CONC`ï¼ˆæµ‹è¯•é…ç½®ï¼‰
- `MAX_MODEL_LEN`, `RANDOM_RANGE_RATIO`, `NUM_PROMPTS`, `RESULT_FILENAME`ï¼ˆæµ‹è¯•å‚æ•°ï¼‰

**æç¤º**ï¼šæ‰€æœ‰ `.sh` è„šæœ¬éƒ½ä½äº `/workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x/` ç›®å½•

---

#### æ–¹å¼ 2: å¤šå¹¶å‘æ‰¹é‡æµ‹è¯•ï¼ˆä¸€é”®æµ‹è¯•æ‰€æœ‰ CONCï¼‰ğŸš€

**é€‚ç”¨åœºæ™¯**ï¼šæ‰¹é‡æµ‹è¯•æ‰€æœ‰ CONC å€¼å¹¶æäº¤åˆ° Leaderboard

**åªéœ€ 3 æ¡å‘½ä»¤ï¼Œè‡ªåŠ¨æµ‹è¯•æ‰€æœ‰é…ç½®å¹¶æäº¤ï¼â­**

```bash
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x

# 1. åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆæ— éœ€æ‰‹åŠ¨ exportï¼‰
source all_conc_var.sh

# 2. å¯åŠ¨ vLLM æœåŠ¡å™¨ï¼ˆé¦–æ¬¡å¯åŠ¨éœ€è¦ 20+ åˆ†é’Ÿ JIT ç¼–è¯‘ï¼‰
bash launch_vllm_server.sh

# ç­‰å¾…æœåŠ¡å™¨å°±ç»ªåï¼ˆçœ‹åˆ° "Uvicorn running..."ï¼‰ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤

# ========== æ¨èï¼šç›´æ¥æµ‹è¯•å¹¶æäº¤ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰========== 

# æäº¤ ISL=1024, OSL=1024 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨è·‘ CONC=4,8,16ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 1024

# æäº¤ ISL=1024, OSL=8192 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨è·‘ CONC=4,8,16ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 8192

# æäº¤ ISL=8192, OSL=1024 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨è·‘ CONC=4,8ï¼Œ~40åˆ†é’Ÿï¼‰
./gptoss_benchmark submit "YourTeam" -isl 8192 -osl 1024

# ========== å¯é€‰ï¼šå¦‚æœåªæƒ³æµ‹è¯•ä¸æäº¤ï¼Œç”¨ perf æ¨¡å¼ ========== 

# æµ‹è¯• ISL=1024, OSL=1024ï¼ˆä¸æäº¤ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark perf -isl 1024 -osl 1024

# æµ‹è¯• ISL=1024, OSL=8192ï¼ˆä¸æäº¤ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark perf -isl 1024 -osl 8192

# æµ‹è¯• ISL=8192, OSL=1024ï¼ˆä¸æäº¤ï¼Œ~40åˆ†é’Ÿï¼‰
./gptoss_benchmark perf -isl 8192 -osl 1024
```

**ç»“æœä¼šè‡ªåŠ¨æäº¤åˆ°å¯¹åº”çš„ Leaderboard**ï¼š
- ISL=1024, OSL=1024 â†’ https://daniehua-gptoss-fp4-vllm-isl1024osl1024.hf.space
- ISL=1024, OSL=8192 â†’ https://daniehua-gptoss-fp4-vllm-isl1024osl8192.hf.space
- ISL=8192, OSL=1024 â†’ https://daniehua-gptoss-fp4-vllm-isl8192osl1024.hf.space

**æäº¤å†…å®¹**ï¼šæ¯ä¸ª CONC é…ç½®ä¼šç‹¬ç«‹æäº¤ï¼ŒåŒ…å«ï¼š
- é˜Ÿä¼åç§° + CONC å€¼
- **MI355X vs B200 ç›´æ¥å¯¹æ¯”**ï¼šE2Eã€ååé‡ã€æ€§èƒ½æ¯”ç‡
- å‡†ç¡®æ€§æŒ‡æ ‡ï¼šbits_per_byte, byte_perplexity, word_perplexity

**CONC èŒƒå›´è¯´æ˜**ï¼š
- ISL=1024, OSL=1024: CONC=4,8,16ï¼ˆ3ä¸ªé…ç½®ï¼‰
- ISL=1024, OSL=8192: CONC=4,8,16ï¼ˆ3ä¸ªé…ç½®ï¼‰
- ISL=8192, OSL=1024: CONC=4,8ï¼ˆ2ä¸ªé…ç½®ï¼‰âš ï¸ æ³¨æ„ï¼š8192-1024 åªæµ‹è¯• CONC=4,8

## æµ‹è¯•æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | å‘½ä»¤ç¤ºä¾‹ | è¿è¡Œå†…å®¹ | è€—æ—¶ï¼ˆå•é…ç½®ï¼‰| ä½¿ç”¨åœºæ™¯ |
|------|---------|---------|-------------|---------|
| **submit** â­ | `./gptoss_benchmark submit "Team"` | å‡†ç¡®æ€§ + æ€§èƒ½ + æäº¤ | ~15-20åˆ†é’Ÿ | **æ¨èï¼šä¸€æ­¥åˆ°ä½ï¼Œå®æ—¶æŸ¥çœ‹æ’å** |
| **submit -isl -osl** â­ | `./gptoss_benchmark submit "Team" -isl 1024 -osl 1024` | è‡ªåŠ¨æµ‹è¯• 3 ä¸ª CONC + æäº¤ | ~1å°æ—¶ | **æ¨èï¼šæ‰¹é‡æµ‹è¯•å¹¶æäº¤** |
| **acc** | `./gptoss_benchmark acc` | ä»…å‡†ç¡®æ€§æµ‹è¯• | ~5-10åˆ†é’Ÿ | å¯é€‰ï¼šå¿«é€ŸéªŒè¯å‡†ç¡®æ€§ |
| **perf** | `./gptoss_benchmark perf` | å‡†ç¡®æ€§ + æ€§èƒ½ï¼ˆä¸æäº¤ï¼‰| ~15-20åˆ†é’Ÿ | å¯é€‰ï¼šæµ‹è¯•æ€§èƒ½ä½†ä¸æäº¤ |
| **perf -isl -osl** | `./gptoss_benchmark perf -isl 1024 -osl 1024` | è‡ªåŠ¨æµ‹è¯• 3 ä¸ª CONCï¼ˆä¸æäº¤ï¼‰| ~1å°æ—¶ | å¯é€‰ï¼šæ‰¹é‡æµ‹è¯•ä½†ä¸æäº¤ |

## ä¸¤ç§æµ‹è¯•æ–¹å¼å¯¹æ¯”

| æ–¹å¼ | æ¨èå‘½ä»¤ | é…ç½®æ•° | è€—æ—¶ä¼°ç®— | æ¨èåœºæ™¯ |
|------|---------|-------|---------|---------|
| **æ–¹å¼ 1: å•é…ç½®** â­ | `./gptoss_benchmark submit "Team"` | 1ä¸ª | ~15-20åˆ†é’Ÿ | **å¼€å‘é˜¶æ®µå¿«é€Ÿè¿­ä»£** |
| **æ–¹å¼ 2: å¤šå¹¶å‘** â­ | `./gptoss_benchmark submit "Team" -isl 1024 -osl 1024` | 3ä¸ª | ~1å°æ—¶ | **æ‰¹é‡æµ‹è¯•æ‰€æœ‰CONC** |

**æ¨èå·¥ä½œæµç¨‹** ğŸ¯ï¼š
1. **å¼€å‘é˜¶æ®µ**ï¼šä½¿ç”¨**æ–¹å¼ 1**ï¼ˆå•é…ç½® + submitï¼‰å¿«é€Ÿè¿­ä»£ï¼Œå®æ—¶æŸ¥çœ‹ Leaderboard
2. **æ‰¹é‡æäº¤**ï¼šä½¿ç”¨**æ–¹å¼ 2**ï¼ˆå¤šå¹¶å‘ + submitï¼‰ä¸€æ¬¡æ€§æµ‹è¯•å¹¶æäº¤æ‰€æœ‰é…ç½®

**ä¸ºä»€ä¹ˆç›´æ¥ç”¨ submitï¼Ÿ**
- âœ… submit = å‡†ç¡®æ€§æµ‹è¯• + æ€§èƒ½æµ‹è¯• + è‡ªåŠ¨æäº¤ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰
- âœ… å®æ—¶æŸ¥çœ‹ Leaderboard æ’åï¼Œç«‹å³çŸ¥é“ä¼˜åŒ–æ•ˆæœ
- âœ… èŠ‚çœæ—¶é—´ï¼Œæ— éœ€å…ˆ perf å† submit

## è¯„åˆ†æ ‡å‡†

### æ€§èƒ½æŒ‡æ ‡ï¼ˆä¸»è¦ï¼‰

- **Throughput per GPU** (`tput_per_gpu`) - æƒé‡æœ€é«˜ ğŸ…
  - å•GPUå½’ä¸€åŒ–ååé‡ = `total_token_throughput / 8`
  - ä¸ B200 baseline ç›´æ¥å¯¹æ¯”
- **E2E (median)** (ms) - ç«¯åˆ°ç«¯å»¶è¿Ÿä¸­ä½æ•°
  - ä¸ B200 baseline ç›´æ¥å¯¹æ¯”

### å‡†ç¡®æ€§è¦æ±‚ï¼ˆå¿…é¡»æ»¡è¶³ï¼‰

æ‰€æœ‰æŒ‡æ ‡å¿…é¡»åœ¨åŸºçº¿ Â± 3% èŒƒå›´å†…ï¼š
- bits_per_byte â‰¤ 2.0558 Ã— 1.03 = **2.1175**
- byte_perplexity â‰¤ 4.1577 Ã— 1.03 = **4.2824**
- word_perplexity â‰¤ 222.7893 Ã— 1.03 = **229.4730**

âŒ è¶…å‡ºèŒƒå›´ä¼šç«‹å³ç»ˆæ­¢æµ‹è¯•ï¼Œä¸è¿è¡Œæ€§èƒ½åŸºå‡†

### B200 Baseline å¯¹æ¯” ğŸ“Š

**è‡ªåŠ¨å¯¹æ¯”åŠŸèƒ½**ï¼šæ¯ä¸ªç»“æœ JSON è‡ªåŠ¨åŒ…å« NVIDIA B200 (ä¼šéšç€inferenceMaxä¸Šè®°å½•çš„B200æ€§èƒ½æ•°æ®å‘¨æœŸæ€§åŒæ­¥æ›´æ–°) çš„ baseline æ•°æ®å’Œæ€§èƒ½æ¯”ç‡ï¼

**æ€§èƒ½æ¯”ç‡è§£è¯»**ï¼š
- `tput_per_gpu_ratio_vs_b200_1126 > 1.0` = MI355X ååé‡æ›´é«˜ âœ…
- `median_e2e_ratio_vs_b200_1126 < 1.0` = MI355X å»¶è¿Ÿæ›´ä½ âœ…

è¯¦è§ç»“æœ JSON ä¸­çš„ `b200_baseline_nv1126` å­—æ®µã€‚

## ä¼˜åŒ–æ–¹å‘å»ºè®®

### 1. Kernel ä¼˜åŒ– âš¡
- Attention kernelï¼ˆFlash Attentionã€PagedAttentionï¼‰
- MoE (Mixture of Experts) kernel - GPT-OSS çš„å…³é”®ï¼
- é‡åŒ– kernel (FP4/MXFP4)

### 2. è°ƒåº¦ä¼˜åŒ– ğŸ“Š
- Continuous batching
- Prefill/decode åˆ‡æ¢ç­–ç•¥
- KV cache ç®¡ç†

### 3. å†…å­˜ä¼˜åŒ– ğŸ’¾
- æ˜¾å­˜åˆ†é…ç­–ç•¥
- Paged attention
- CUDA graph / compilation config ä¼˜åŒ–

### 4. ROCm ç‰¹å®šä¼˜åŒ– ğŸ”§
- AMD GPU ç‰¹æ€§åˆ©ç”¨
- HIP/ROCm API ä¼˜åŒ–
- AITER å¼‚æ­¥è¿­ä»£å™¨

### 5. vLLM ç‰¹å®šä¼˜åŒ– ğŸš€
- Async scheduling
- Block manager
- Compilation config è°ƒä¼˜

## å¼€å‘æŠ€å·§

### æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—
tail -f /tmp/vllm-server-*.log

# è¿‡æ»¤é”™è¯¯
tail -f /tmp/vllm-server-*.log | grep -i error
```

### å¤šå¹¶å‘æ‰¹é‡æµ‹è¯•ï¼ˆæ¨èï¼‰â­

```bash
# 1. åŠ è½½ç¯å¢ƒå˜é‡
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x
source all_conc_var.sh

# 2. å¯åŠ¨ vLLM æœåŠ¡å™¨
bash launch_vllm_server.sh

# ç­‰å¾…æœåŠ¡å™¨å°±ç»ªåï¼ˆæŸ¥çœ‹æ—¥å¿— "Uvicorn running..."ï¼‰ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤

# ========== æ¨èï¼šç›´æ¥æµ‹è¯•å¹¶æäº¤ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰========== 

# æäº¤ ISL=1024, OSL=1024 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨æµ‹è¯• CONC=4,8,16ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 1024

# æäº¤ ISL=1024, OSL=8192 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨æµ‹è¯• CONC=4,8,16ï¼Œ~1å°æ—¶ï¼‰
./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 8192

# æäº¤ ISL=8192, OSL=1024 çš„æ‰€æœ‰ç»“æœï¼ˆè‡ªåŠ¨æµ‹è¯• CONC=4,8ï¼Œ~40åˆ†é’Ÿï¼‰
./gptoss_benchmark submit "YourTeam" -isl 8192 -osl 1024
```

**æ¯æ¡å‘½ä»¤ä¼šè‡ªåŠ¨**ï¼š
- âœ… æµ‹è¯•å¯¹åº”çš„ CONC å€¼ï¼ˆ1024-1024å’Œ1024-8192: 3ä¸ªï¼Œ8192-1024: 2ä¸ªï¼‰
- âœ… è¿è¡Œå‡†ç¡®æ€§ + æ€§èƒ½æµ‹è¯•
- âœ… è‡ªåŠ¨æäº¤åˆ°å¯¹åº”çš„ ISL-OSL Leaderboard
- âœ… ä¿å­˜æ‰€æœ‰ç»“æœåˆ°ç‹¬ç«‹ç›®å½•
- âœ… ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š

**Leaderboard è‡ªåŠ¨è·¯ç”±**ï¼š
- `ISL=1024, OSL=1024` â†’ https://daniehua-gptoss-fp4-vllm-isl1024osl1024.hf.space
- `ISL=1024, OSL=8192` â†’ https://daniehua-gptoss-fp4-vllm-isl1024osl8192.hf.space
- `ISL=8192, OSL=1024` â†’ https://daniehua-gptoss-fp4-vllm-isl8192osl1024.hf.space

**ç»“æœè¾“å‡ºç¤ºä¾‹**ï¼š
```
============================================
Multi-Concurrency Testing Mode
============================================
ISL: 1024
OSL: 1024
Mode: submit
CONC values: 4, 8, 16
Team: YourTeam
Leaderboard: https://daniehua-gptoss-fp4-vllm-isl1024osl1024.hf.space
============================================

Results directory: batch_isl1024_osl1024_20251127_150000

============================================
Testing CONC=4
============================================
... (è¿è¡Œæµ‹è¯•) ...
âœ“ CONC=4: PASSED (180s)

============================================
Testing CONC=8
============================================
... (ç»§ç»­æµ‹è¯•å…¶ä»– CONC å€¼) ...

============================================
Multi-Concurrency Test Complete!
============================================
Total tests: 3
Passed: 3
Failed: 0

Results saved in: batch_isl1024_osl1024_20251127_150000/
============================================
```

**å¼€å‘é˜¶æ®µå¿«é€ŸéªŒè¯**ï¼š
```bash
# æ¨èï¼šç›´æ¥æµ‹è¯•å¹¶æäº¤ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰â­
./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 1024

# å¯é€‰ï¼šåªæµ‹è¯•å‡†ç¡®æ€§ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
./gptoss_benchmark acc -isl 1024 -osl 1024

# å¯é€‰ï¼šå®Œæ•´æµ‹è¯•ä½†ä¸æäº¤
./gptoss_benchmark perf -isl 1024 -osl 1024
```

## å¸¸è§é—®é¢˜

### Q: å‡†ç¡®æ€§éªŒè¯å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

```
ERROR: Accuracy validation FAILED!
bits_per_byte: 6.5000 > 5.1500
```

**è§£å†³**ï¼šä½ çš„ä¼˜åŒ–å½±å“äº†æ¨¡å‹è´¨é‡ï¼Œéœ€è¦è°ƒæ•´ç®—æ³•æˆ–å‚æ•°

### Q: å¦‚ä½•åªå¯åŠ¨æœåŠ¡å™¨ä¸è¿è¡Œæµ‹è¯•ï¼Ÿ

```bash
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x

# åŠ è½½ç¯å¢ƒå˜é‡
source all_conc_var.sh

# å¯åŠ¨æœåŠ¡å™¨
bash launch_vllm_server.sh
```

æœåŠ¡å™¨ä¼šåœ¨å‰å°è¿è¡Œï¼Œæ—¥å¿—ç›´æ¥è¾“å‡ºåˆ°ç»ˆç«¯ã€‚

### Q: ä¿®æ”¹äº† C++ ä»£ç ä½†æ²¡ç”Ÿæ•ˆï¼Ÿ

éœ€è¦é‡æ–°ç¼–è¯‘ï¼š

```bash
cd /workspace/vllm
rm -rf build/
pip uninstall -y vllm
VLLM_TARGET_DEVICE=rocm python3 setup.py develop
```

### Q: å¤šå¹¶å‘æµ‹è¯•ä¸­é€”å¤±è´¥äº†æ€ä¹ˆåŠï¼Ÿ

æµ‹è¯•ä¼šç»§ç»­è¿è¡Œå‰©ä½™ CONC é…ç½®ï¼Œæœ€åç”Ÿæˆå®Œæ•´æŠ¥å‘Šã€‚å¤±è´¥çš„é…ç½®ä¼šæ ‡è®°ä¸º "FAILED"ã€‚

æŸ¥çœ‹å¤±è´¥åŸå› ï¼š
```bash
# æŸ¥çœ‹æ±‡æ€»
cat batch_isl*_osl*/summary.txt

# æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—
tail -f /tmp/vllm-server-*.log
```

### Q: å¦‚ä½•åªæµ‹è¯•ç‰¹å®šçš„ CONC å€¼ï¼Ÿ

ä½¿ç”¨å•é…ç½®æ¨¡å¼ï¼š

```bash
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x

# 1. ç¼–è¾‘ specific_conc_var.shï¼Œä¿®æ”¹ CONC å€¼
vim specific_conc_var.sh  # ä¿®æ”¹ CONC=16

# 2. åŠ è½½ç¯å¢ƒå˜é‡
source specific_conc_var.sh

# 3. æ¨èï¼šç›´æ¥æµ‹è¯•å¹¶æäº¤ â­
./gptoss_benchmark submit "YourTeam"
```

æˆ–è€…ç›´æ¥æ‰‹åŠ¨è®¾ç½®ï¼š
```bash
cd /workspace/amdgpu_inferencemax_bounty/gptoss-fp4-vllm-mi355x
source specific_conc_var.sh
export CONC=16  # è¦†ç›–é»˜è®¤å€¼ï¼Œåªæµ‹è¯• CONC=16
export NUM_PROMPTS=160  # GPT-OSS: CONC * 10

# æ¨èï¼šç›´æ¥æäº¤
./gptoss_benchmark submit "YourTeam"

# å¯é€‰ï¼šåªæµ‹è¯•ä¸æäº¤
./gptoss_benchmark perf
```

### Q: æµ‹è¯•éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**å•é…ç½®æµ‹è¯•**ï¼š
- **submit æ¨¡å¼**: ~15-20åˆ†é’Ÿ â­ **æ¨èï¼šä¸€æ­¥åˆ°ä½**
- **acc æ¨¡å¼**: ~5-10åˆ†é’Ÿï¼ˆå¯é€‰ï¼šä»…éªŒè¯å‡†ç¡®æ€§ï¼‰
- **perf æ¨¡å¼**: ~15-20åˆ†é’Ÿï¼ˆå¯é€‰ï¼šæµ‹è¯•ä½†ä¸æäº¤ï¼‰

**å¤šå¹¶å‘æµ‹è¯•ï¼ˆæ¯ä¸ª ISL-OSL ç»„åˆï¼‰**ï¼š
- **ISL=1024, OSL=1024 (3ä¸ªCONC)**: ~15-20åˆ†é’Ÿ/CONC Ã— 3 = **~1å°æ—¶** â­
- **ISL=1024, OSL=8192 (3ä¸ªCONC)**: ~15-20åˆ†é’Ÿ/CONC Ã— 3 = **~1å°æ—¶** â­
- **ISL=8192, OSL=1024 (2ä¸ªCONC)**: ~15-20åˆ†é’Ÿ/CONC Ã— 2 = **~40åˆ†é’Ÿ** â­

**å…¨éƒ¨ 3 ä¸ª ISL-OSL ç»„åˆ**ï¼ˆ8 ä¸ªé…ç½®ï¼‰ï¼š
- **submit æ¨¡å¼**: ~1å°æ—¶ + ~1å°æ—¶ + ~40åˆ†é’Ÿ = **~2.5-3å°æ—¶** â­

**æ¨èå·¥ä½œæµ** ğŸ¯ï¼š
1. **å¼€å‘é˜¶æ®µ**ï¼šå•é…ç½® `submit "YourTeam"` å¿«é€Ÿè¿­ä»£ï¼ˆ~15-20åˆ†é’Ÿ/æ¬¡ï¼‰
   - ç«‹å³çœ‹åˆ° Leaderboard æ’åï¼Œå¿«é€ŸéªŒè¯ä¼˜åŒ–æ•ˆæœ
2. **æ‰¹é‡æäº¤**ï¼šå¤šå¹¶å‘ `submit "YourTeam" -isl -osl` æäº¤æ‰€æœ‰é…ç½®ï¼ˆ~1å°æ—¶/ç»„åˆï¼‰
   - ä¸€æ¬¡æ€§å®Œæˆæµ‹è¯•å’Œæäº¤ï¼Œå¯åœ¨å¤œé—´è¿è¡Œ

ğŸ’¡ **ä¸ºä»€ä¹ˆç›´æ¥ç”¨ submitï¼Ÿ**
- âœ… ä¸€æ­¥åˆ°ä½ï¼Œæ— éœ€å…ˆ perf å† submit
- âœ… å®æ—¶æŸ¥çœ‹æ’åï¼Œç«‹å³çŸ¥é“ä¼˜åŒ–æ•ˆæœ
- âœ… èŠ‚çœæ—¶é—´ï¼Œé¿å…é‡å¤è¿è¡Œ

### Q: GPT-OSS å’Œ DeepSeek-R1 æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**ä¸»è¦åŒºåˆ«**ï¼š

| ç‰¹æ€§ | GPT-OSS | DeepSeek-R1 |
|------|---------|------------|
| æ¨¡å‹å¤§å° | 120B | ~670B |
| æ¶æ„ | MoE (Mixture of Experts) | Dense |
| æ¡†æ¶ | vLLM | SGLang |
| CONC èŒƒå›´ | 4-16 (8192-1024: 4-8) | 4-64 |
| NUM_PROMPTS | CONC Ã— 10 | CONC Ã— 50 (1024-1024/8192-1024) / CONC Ã— 20 (1024-8192) |
| ä¼˜åŒ–é‡ç‚¹ | MoE kernel, vLLM è°ƒåº¦ | é•¿ä¸Šä¸‹æ–‡, chunked prefill |

**ä¼˜åŒ–å»ºè®®**ï¼š
- GPT-OSSï¼šé‡ç‚¹ä¼˜åŒ– MoE kernelï¼ˆAITER æä¾›çš„ A16W4 fused MoEï¼‰
- è°ƒæ•´ compilation config ä¸­çš„ compile_sizes å’Œ cudagraph_capture_sizes


## æ¨èçš„å·¥ä½œæµç¨‹

```
ç¬¬1è½®ï¼šç†Ÿæ‚‰åŸºçº¿
  â”œâ”€ è¿è¡ŒåŸºçº¿æµ‹è¯•ï¼š./gptoss_benchmark submit "YourTeam"
  â”œâ”€ äº†è§£ vLLM æ¶æ„
  â””â”€ æŸ¥çœ‹ Leaderboard åŸºçº¿æ€§èƒ½

ç¬¬2è½®ï¼šä½é£é™©ä¼˜åŒ–
  â”œâ”€ è°ƒæ•´ compilation config
  â”œâ”€ ä¼˜åŒ– GPU memory utilization
  â””â”€ å¿«é€ŸéªŒè¯ï¼š./gptoss_benchmark submit "YourTeam"ï¼ˆ~15-20åˆ†é’Ÿï¼‰

ç¬¬3è½®ï¼šAMD GPU Kernel ä¼˜åŒ–
  â”œâ”€ Profile æ‰¾ç“¶é¢ˆ
  â”œâ”€ ä¼˜åŒ– MoE kernel (å…³é”®ï¼)
  â””â”€ å®æ—¶å¯¹æ¯”ï¼š./gptoss_benchmark submit "YourTeam"ï¼ŒæŸ¥çœ‹ Leaderboard

ç¬¬4è½®ï¼šç³»ç»Ÿä¼˜åŒ–
  â”œâ”€ Async scheduling
  â”œâ”€ Block manager
  â””â”€ ç«¯åˆ°ç«¯è°ƒä¼˜ï¼Œæ¯æ¬¡ä¼˜åŒ–åç«‹å³æäº¤éªŒè¯

ç¬¬5è½®ï¼šæ‰¹é‡æäº¤
  â”œâ”€ æµ‹è¯•æ‰€æœ‰ ISL-OSL ç»„åˆ
  â”œâ”€ ./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 1024
  â”œâ”€ ./gptoss_benchmark submit "YourTeam" -isl 1024 -osl 8192
  â””â”€ ./gptoss_benchmark submit "YourTeam" -isl 8192 -osl 1024
```

**å…³é”®ä¼˜åŠ¿**ï¼šæ¯æ¬¡ä¼˜åŒ–åç›´æ¥ submitï¼Œå®æ—¶æŸ¥çœ‹ Leaderboard æ’åï¼Œå¿«é€Ÿè¿­ä»£ï¼

## èµ„æºé“¾æ¥

- ğŸ“– [InferenceMAX å®˜æ–¹ä»“åº“](https://github.com/semianalysis/InferenceMAX) - æµ‹è¯•åŸºå‡†å‚è€ƒ
- ğŸ”§ [vLLM GitHub](https://github.com/vllm-project/vllm) - æ¨ç†æ¡†æ¶
- ğŸ”§ [AITER GitHub](https://github.com/ROCm/aiter) - AMD GPU ç®—å­åº“
- ğŸ“Š Leaderboards:
  - [ISL=1024, OSL=1024](https://daniehua-gptoss-fp4-vllm-isl1024osl1024.hf.space)
  - [ISL=1024, OSL=8192](https://daniehua-gptoss-fp4-vllm-isl1024osl8192.hf.space)
  - [ISL=8192, OSL=1024](https://daniehua-gptoss-fp4-vllm-isl8192osl1024.hf.space)


**ç¥å‚èµ›é¡ºåˆ©ï¼ğŸš€**

è®°ä½ï¼š
- **ç›´æ¥ç”¨ submit mode**ï¼šä¸€æ­¥åˆ°ä½ï¼Œå®æ—¶æŸ¥çœ‹æ’å â­
- **æ€§èƒ½é‡è¦ï¼Œå‡†ç¡®æ€§æ›´é‡è¦ï¼** æ‰€æœ‰ä¼˜åŒ–å¿…é¡»é€šè¿‡å‡†ç¡®æ€§éªŒè¯
- **å¿«é€Ÿè¿­ä»£**ï¼šæ¯æ¬¡ä¼˜åŒ–åç«‹å³ submitï¼Œç«‹å³çœ‹åˆ°æ•ˆæœ
- **é‡ç‚¹ä¼˜åŒ– MoE kernel**ï¼šGPT-OSS æ˜¯ MoE æ¨¡å‹ï¼ŒMoE kernel æ€§èƒ½è‡³å…³é‡è¦ï¼

