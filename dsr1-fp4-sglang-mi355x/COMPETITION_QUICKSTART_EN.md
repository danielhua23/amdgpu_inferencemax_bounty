# ğŸ† Competition Quick Start Guide

## ğŸ“‘ Table of Contents

- [Objective](#objective)
- [ğŸ“Œ Important Notice](#-important-notice)
- [Core Files](#core-files)
- [Quick Start (5 Steps)](#quick-start-5-steps)
  - [1ï¸âƒ£ Prepare Working Directory (on Host Machine)](#1ï¸âƒ£-prepare-working-directory-on-host-machine)
  - [2ï¸âƒ£ Launch Development Container](#2ï¸âƒ£-launch-development-container)
  - [3ï¸âƒ£ Install Editable SGLang in Container](#3ï¸âƒ£-install-editable-sglang-in-container)
  - [4ï¸âƒ£ Example: How to Recompile After Code Modifications](#4ï¸âƒ£-example-how-to-recompile-after-code-modifications)
  - [5ï¸âƒ£ Test Optimization Results](#5ï¸âƒ£-test-optimization-results)
- [Test Mode Comparison](#test-mode-comparison)
- [Two Testing Approaches Comparison](#two-testing-approaches-comparison)
- [Evaluation Criteria](#evaluation-criteria)
  - [Performance Metrics (Primary)](#performance-metrics-primary)
  - [Accuracy Requirements (Must Meet)](#accuracy-requirements-must-meet)
  - [B200 Baseline Comparison ğŸ“Š](#b200-baseline-comparison-)
- [Optimization Directions](#optimization-directions)
- [Development Tips](#development-tips)
- [FAQ](#faq)
- [Recommended Workflow](#recommended-workflow)
- [Resource Links](#resource-links)

---

## Objective

Optimize inference performance of dsr1-fp4 model using sglang on AMD MI355X GPUs while maintaining model accuracy.

## ğŸ“Œ Important Notice

This competition's benchmark **aligns with the [InferenceMAX](https://github.com/InferenceMAX/InferenceMAX)** repository's AMD MI355X test configuration and will be synchronized with InferenceMAX updates.

## Core Files

| File | Purpose |
|------|------|
| `amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/launch_sglang_server.sh` | Launch SGLang server |
| `amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/dsr1_benchmark` | Run tests and submit results (binary file)|
| `amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/all_conc_var.sh` | Multi-concurrency test environment variables |
| `amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/specific_conc_var.sh` | Single configuration test environment variables |

## Quick Start (5 Steps)

### 1ï¸âƒ£ Prepare Working Directory (on Host Machine)

```bash
# Create working directory on host machine
mkdir -p ~/competition
cd ~/competition

# Clone SGLang (you will optimize based on this)
git clone https://github.com/sgl-project/sglang.git

# Clone AITER (AMD GPU operator library)
git clone --recursive https://github.com/ROCm/aiter.git

# Clone scripts repository
git clone https://github.com/danielhua23/amdgpu_inferencemax_bounty.git
```

### 2ï¸âƒ£ Launch Development Container

**Note**: Replace `HF_TOKEN` with your Hugging Face Token.

```bash
docker run -it \
  --name sglang-dev \
  --ipc=host --shm-size=16g --network=host \
  --privileged --cap-add=CAP_SYS_ADMIN \
  --device=/dev/kfd --device=/dev/dri --device=/dev/mem \
  --cap-add=SYS_PTRACE --security-opt seccomp=unconfined \
  -v /nfsdata/hf_hub_cache-1/:/root/.cache/huggingface \
  -v ~/competition:/workspace \
  -v ~/competition/aiter:/workspace/aiter \
  -v ~/competition/sglang:/workspace/sglang \
  -e HF_TOKEN=your_huggingface_token_here \
  rocm/7.0:rocm7.0_ubuntu_22.04_sgl-dev-v0.5.2-rocm7.0-mi35x-20250915 \
  /bin/bash
```

**Mount Instructions**:
- Host `~/competition/*` â†’ Container `/workspace/*`
- Code modifications on host machine take effect immediately in container (and vice versa)
- Test scripts are located in `/workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/` directory

### 3ï¸âƒ£ Install Editable SGLang in Container

> refer to https://docs.sglang.io/platforms/amd_gpu.html

```bash
# Uninstall existing sglang-related libraries in container
pip uninstall aiter
pip uninstall sglang
pip uninstall sgl-kernel
# Enter aiter directory
cd /workspace/aiter
python3 setup.py develop
```
verify if newest aiter is installed
```bash
root@mi355:/workspace# pip list | grep aiter
aiter                             0.1.7.post3.dev39+g1f5b378dc        /workspace/aiter
```
lets continue install sgl-kernel
```bash
# Enter SGLang directory
cd /workspace/sglang

# Compile sgl-kernel
pip install --upgrade pip
cd sgl-kernel
python setup_rocm.py install
```
verify if newest sgl-kernel is installed
```bash
root@mi355:/workspace# pip list | grep sgl-kernel
sgl-kernel                        0.3.18
```
lets continue install sglang python pkg
```bash
# Install sglang python package
cd ..
rm -rf python/pyproject.toml && mv python/pyproject_other.toml python/pyproject.toml
pip install -e "python[all_hip]"

# verify
python -c "import sglang; print(sglang.__file__)"
# expect ouput: /workspace/sglang/python/sglang/__init__.py
```

### 4ï¸âƒ£ Example: How to Recompile After Code Modifications

```bash
# Edit in container or host machine (VS Code)
# Example: Optimize scheduler
cd /workspace/sglang
vim python/sglang/srt/managers/scheduler.py

# If you modified C++/CUDA/HIP code, recompile:
cd sgl-kernel
rm -rf build/
pip uninstall sgl-kernel
python setup_rocm.py install
```

### 5ï¸âƒ£ Test Optimization Results

#### Recommended Workflow â­

```
Development Phase (Rapid Iteration)
  â†“
1. Single Config Test & Submit (Approach 1)
   - Use submit mode to test single value (~20 mins)
   - Auto-submit to Leaderboard, view ranking in real-time
  â†“
2. Multi-Concurrency Batch Test & Submit (Approach 2)
   - Use submit mode to test all CONC (~2 hours/ISL-OSL)
   - Auto-submit all results
  â†“
Done! View Leaderboard rankings in real-time ğŸ‰
```

**Why use submit mode directly?**
- âœ… **All-in-one**: submit = accuracy test + performance test + auto-submit
- âœ… **Real-time feedback**: See Leaderboard ranking immediately, rapid iteration
- âœ… **Save time**: No need to run perf then submit, just submit directly

---

#### Approach 1: Single Config Test (Quick Validation) âš¡

**Use Case**: Quickly validate single CONC config performance during development

```bash
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x

# 1. Load environment variables (no manual export needed)
source specific_conc_var.sh

# 2. Launch SGLang server (first launch needs 20+ mins for JIT compilation)
bash launch_sglang_server.sh

# Wait for server ready (see "application startup..."ï¼‰, then open a new window to run tests
# 3. go into new windown and reload env var
docker exec -ti sglang-dev bash
source specific_conc_var.sh
# 4. Recommended: Test and submit directly (~20-30 mins) â­
./dsr1_benchmark submit "YourTeam"

# Optional: Quick accuracy validation only (~5-10 mins)
./dsr1_benchmark acc

# Optional: Test performance without submitting (~20-30 mins)
./dsr1_benchmark perf
```

**Environment Variables**: `specific_conc_var.sh` sets:
- `MODEL`, `PORT`, `TP` (server configuration)
- `ISL`, `OSL`, `CONC` (test configuration)
- `RANDOM_RANGE_RATIO`, `NUM_PROMPTS`, `RESULT_FILENAME` (test parameters)

**Tip**: All `.sh` scripts are located in `/workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x/` directory

---

#### Approach 2: Multi-Concurrency Batch Testing (Test All CONC with One Command) ğŸš€

**Use Case**: Batch test all CONC values and submit to Leaderboard

**Only 3 commands to auto-test all 15 configurations and submit! â­**

```bash
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x

# 1. Load environment variables (no manual export needed)
source all_conc_var.sh

# 2. Launch SGLang server (first launch needs 20+ mins for JIT compilation)
bash launch_sglang_server.sh

# ========== Recommended: Test and submit directly (all-in-one) ========== 
# Wait for server ready (see "application startup..."ï¼‰, then open a new window to run tests
# 3. go into new windown and reload env var
docker exec -ti sglang-dev bash
source all_conc_var.sh

# 4. Submit all results for ISL=1024, OSL=1024 (auto-run CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 1024

# Submit all results for ISL=1024, OSL=8192 (auto-run CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 8192

# Submit all results for ISL=8192, OSL=1024 (auto-run CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 8192 -osl 1024

# ========== Optional: Test without submitting, use perf mode ========== 

# Test ISL=1024, OSL=1024 (no submit, ~2 hours)
./dsr1_benchmark perf -isl 1024 -osl 1024

# Test ISL=1024, OSL=8192 (no submit, ~2 hours)
./dsr1_benchmark perf -isl 1024 -osl 8192

# Test ISL=8192, OSL=1024 (no submit, ~2 hours)
./dsr1_benchmark perf -isl 8192 -osl 1024
```

**Results auto-submit to corresponding Leaderboards**:
- ISL=1024, OSL=1024 â†’ https://daniehua-dsr1-fp4-sgl-isl1024osl1024.hf.space
- ISL=1024, OSL=8192 â†’ https://daniehua-dsr1-fp4-sgl-isl1024osl8192.hf.space
- ISL=8192, OSL=1024 â†’ https://daniehua-dsr1-fp4-sgl-isl8192osl1024.hf.space

**Submission Content**: Each CONC configuration submits independently, including:
- Team name + CONC value
- **MI355X vs B200 Direct Comparison**: E2E, throughput, performance ratios
- Accuracy metrics: bits_per_byte, byte_perplexity, word_perplexity


## Test Mode Comparison

| Mode | Command Example | What Runs | Time (Single Config) | Use Case |
|------|---------|---------|-------------|---------|
| **submit** â­ | `./dsr1_benchmark submit "Team"` | Accuracy + Performance + Submit | ~20-30 mins | **Recommended: All-in-one, view ranking real-time** |
| **submit -isl -osl** â­ | `./dsr1_benchmark submit "Team" -isl 1024 -osl 1024` | Auto-test 5 CONC + Submit | ~2 hours | **Recommended: Batch test and submit** |
| **acc** | `./dsr1_benchmark acc` | Accuracy test only | ~5-10 mins | Optional: Quick accuracy validation |
| **perf** | `./dsr1_benchmark perf` | Accuracy + Performance (no submit) | ~20-30 mins | Optional: Test performance without submitting |
| **perf -isl -osl** | `./dsr1_benchmark perf -isl 1024 -osl 1024` | Auto-test 5 CONC (no submit) | ~2 hours | Optional: Batch test without submitting |

## Two Testing Approaches Comparison

| Approach | Recommended Command | Configs | Time Estimate | Recommended Scenario |
|------|---------|-------|---------|---------|
| **Approach 1: Single Config** â­ | `./dsr1_benchmark submit "Team"` | 1 | ~20 mins | **Development phase rapid iteration** |
| **Approach 2: Multi-Concurrency** â­ | `./dsr1_benchmark submit "Team" -isl 1024 -osl 1024` | 5 | ~2 hours | **Batch test all CONC** |

**Recommended Workflow** ğŸ¯:
1. **Development Phase**: Use **Approach 1** (single config + submit) for rapid iteration, view Leaderboard real-time
2. **Batch Submission**: Use **Approach 2** (multi-conc + submit) to test and submit all configurations at once

**Why use submit directly?**
- âœ… submit = accuracy test + performance test + auto-submit (all-in-one)
- âœ… View Leaderboard ranking real-time, immediately know optimization effects
- âœ… Save time, no need to run perf then submit

## Evaluation Criteria

### Performance Metrics (Primary)

- **Throughput per GPU** (`tput_per_gpu`) - Highest weight ğŸ…
  - Single GPU normalized throughput = `total_token_throughput / 8`
  - Direct comparison with B200 baseline
- **E2E (median)** (ms) - End-to-end latency median
  - Direct comparison with B200 baseline

### Accuracy Requirements (Must Meet)

All metrics must be within baseline Â± 3% range:
- bits_per_byte â‰¤ 0.4485 Ã— 1.03 = **0.4620**
- byte_perplexity â‰¤ 1.3646 Ã— 1.03 = **1.4055**
- word_perplexity â‰¤ 3.2522 Ã— 1.03 = **3.3498**

âŒ Exceeding range will immediately terminate testing, performance benchmark will not run

### B200 Baseline Comparison ğŸ“Š

**Auto-comparison feature**: Each result JSON automatically includes NVIDIA B200 (periodically synced with InferenceMAX B200 performance data) baseline data and performance ratios!

**Performance Ratio Interpretation**:
- `tput_per_gpu_ratio_vs_b200_1126 > 1.0` = MI355X has higher throughput âœ…
- `median_e2e_ratio_vs_b200_1126 < 1.0` = MI355X has lower latency âœ…

See `b200_baseline_nv1126` field in result JSON for details.

## Optimization Directions

### 1. Kernel Optimization âš¡
- Attention kernel
- MoE (Mixture of Experts) kernel  
- Quantization kernel (FP4/FP8)

### 2. Scheduling Optimization ğŸ“Š
- Batch scheduler
- Prefill/decode switching strategy
- KV cache management

### 3. Memory Optimization ğŸ’¾
- Memory allocation strategy
- Reduce memory fragmentation
- Paged attention

### 4. ROCm-Specific Optimization ğŸ”§
- Leverage AMD GPU features
- HIP/ROCm API optimization
- AITER async iterator

## Development Tips

### View Logs

```bash
# View server logs in real-time
tail -f /tmp/sglang-server-*.log

# Filter errors
tail -f /tmp/sglang-server-*.log | grep -i error
```

### Multi-Concurrency Batch Testing (Recommended) â­

```bash
# 1. Load environment variables
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x
source all_conc_var.sh

# 2. Launch SGLang server
bash launch_sglang_server.sh

# ========== Recommended: Test and submit directly (all-in-one) ========== 
# Wait for server ready (see "application startup..."ï¼‰, then open a new window to run tests
# 3. go into new window and reload env var
docker exec -ti sglang-dev bash
source specific_conc_var.sh
# 4.
# Submit all results for ISL=1024, OSL=1024 (auto-test CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 1024

# Submit all results for ISL=1024, OSL=8192 (auto-test CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 8192

# Submit all results for ISL=8192, OSL=1024 (auto-test CONC=4,8,16,32,64, ~2 hours)
./dsr1_benchmark submit "YourTeam" -isl 8192 -osl 1024
```

**Each command will automatically**:
- âœ… Test 5 CONC values (4, 8, 16, 32, 64)
- âœ… Run accuracy + performance tests
- âœ… Auto-submit to corresponding ISL-OSL Leaderboard
- âœ… Save all results to independent directory
- âœ… Generate summary report

**Leaderboard Auto-Routing**:
- `ISL=1024, OSL=1024` â†’ https://daniehua-dsr1-fp4-sgl-isl1024osl1024.hf.space
- `ISL=1024, OSL=8192` â†’ https://daniehua-dsr1-fp4-sgl-isl1024osl8192.hf.space
- `ISL=8192, OSL=1024` â†’ https://daniehua-dsr1-fp4-sgl-isl8192osl1024.hf.space

**Result Output Example**:
```
============================================
Multi-Concurrency Testing Mode
============================================
ISL: 1024
OSL: 1024
Mode: submit
CONC values: 4, 8, 16, 32, 64
Team: YourTeam
Leaderboard: https://daniehua-dsr1-fp4-sgl-isl1024osl1024.hf.space
============================================

Results directory: batch_isl1024_osl1024_20251125_150000

============================================
Testing CONC=4
============================================
... (running tests) ...
âœ“ CONC=4: PASSED (180s)

============================================
Testing CONC=8
============================================
... (continue testing other CONC values) ...

============================================
Multi-Concurrency Test Complete!
============================================
Total tests: 5
Passed: 5
Failed: 0

Results saved in: batch_isl1024_osl1024_20251125_150000/
============================================
```

**Development Phase Quick Validation**:
```bash
# Recommended: Test and submit directly (all-in-one) â­
./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 1024

# Optional: Accuracy test only (quick validation)
./dsr1_benchmark acc -isl 1024 -osl 1024

# Optional: Full test without submitting
./dsr1_benchmark perf -isl 1024 -osl 1024
```

## FAQ

### Q: What if accuracy validation fails?

```
ERROR: Accuracy validation FAILED!
bits_per_byte: 6.5000 > 5.1500
```

**Solution**: Your optimization affected model quality, need to adjust algorithm or parameters

### Q: How to launch server only without running tests?

```bash
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x

# Load environment variables
source all_conc_var.sh

# Launch server
bash launch_sglang_server.sh
```

Server will run in foreground, logs output directly to terminal.

### Q: C++ code modifications not taking effect?

Need to recompile:

```bash
cd /workspace/sglang/sgl-kernel
rm -rf build/
pip uninstall sgl-kernel
python setup_rocm.py install
```

### Q: What if multi-concurrency test fails midway?

Test will continue with remaining CONC configurations, generating complete report at the end. Failed configurations will be marked as "FAILED".

View failure reasons:
```bash
# View summary
cat batch_isl*_osl*/summary.txt

# View server logs
tail -f /tmp/sglang-server-*.log
```

### Q: How to test specific CONC value only?

Use single configuration mode:

```bash
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x

# 1. Edit specific_conc_var.sh to modify CONC value
vim specific_conc_var.sh  # Modify CONC=64

# 2. Load environment variables
source specific_conc_var.sh

# 3. Recommended: Test and submit directly â­
./dsr1_benchmark submit "YourTeam"
```

Or set manually:
```bash
cd /workspace/amdgpu_inferencemax_bounty/dsr1-fp4-sglang-mi355x
source specific_conc_var.sh
export CONC=64  # Override default, test CONC=64 only
export NUM_PROMPTS=3200

# Recommended: Submit directly
./dsr1_benchmark submit "YourTeam"

# Optional: Test without submitting
./dsr1_benchmark perf
```

### Q: How long do tests take?

**Single Configuration Test**:
- **submit mode**: ~20-30 mins â­ **Recommended: All-in-one**
- **acc mode**: ~5-10 mins (Optional: Accuracy validation only)
- **perf mode**: ~20-30 mins (Optional: Test without submitting)

**Multi-Concurrency Test (per ISL-OSL combination, 5 CONC values)**:
- **submit -isl -osl**: ~20-30 mins/CONC Ã— 5 = **~2 hours** â­ **Recommended**
- **acc -isl -osl**: ~5-10 mins/CONC Ã— 5 = **25-50 mins** (Optional)
- **perf -isl -osl**: ~20-30 mins/CONC Ã— 5 = **~2 hours** (Optional)

**All 3 ISL-OSL Combinations** (15 configurations):
- **submit mode**: ~2 hours Ã— 3 = **~6 hours** â­

**Recommended Workflow** ğŸ¯:
1. **Development Phase**: Single config `submit "YourTeam"` rapid iteration (~20 mins/time)
   - See Leaderboard ranking immediately, quickly validate optimization effects
2. **Batch Submission**: Multi-conc `submit "YourTeam" -isl -osl` submit all configs (~2 hours/combination)
   - Complete testing and submission at once, can run overnight

ğŸ’¡ **Why use submit directly?**
- âœ… All-in-one, no need to run perf then submit
- âœ… View ranking real-time, immediately know optimization effects
- âœ… Save time, avoid redundant runs



## Recommended Workflow

```
Round 1: Familiarize with Baseline
  â”œâ”€ Run baseline test: ./dsr1_benchmark submit "YourTeam"
  â”œâ”€ Understand SGLang architecture
  â””â”€ View Leaderboard baseline performance

Round 2: Low-Risk Optimization
  â”œâ”€ Adjust hyperparameters
  â”œâ”€ Optimize configuration
  â””â”€ Quick validation: ./dsr1_benchmark submit "YourTeam" (~20 mins)

Round 3: AMD GPU Kernel Optimization
  â”œâ”€ Profile to find bottlenecks
  â”œâ”€ Optimize critical kernels
  â””â”€ Real-time comparison: ./dsr1_benchmark submit "YourTeam", view Leaderboard

Round 4: System Optimization
  â”œâ”€ Memory management
  â”œâ”€ Communication optimization
  â””â”€ End-to-end tuning, submit for validation after each optimization

Round 5: Batch Submission
  â”œâ”€ Test all ISL-OSL combinations
  â”œâ”€ ./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 1024
  â”œâ”€ ./dsr1_benchmark submit "YourTeam" -isl 1024 -osl 8192
  â””â”€ ./dsr1_benchmark submit "YourTeam" -isl 8192 -osl 1024
```

**Key Advantage**: Submit directly after each optimization, view Leaderboard ranking real-time, rapid iteration!

## Resource Links

- ğŸ“– [InferenceMAX Official Repository](https://github.com/InferenceMAX/InferenceMAX) - Benchmark reference
- ğŸ”§ [SGLang GitHub](https://github.com/sgl-project/sglang) - Inference framework
- ğŸ“Š Leaderboards:
  - [ISL=1024, OSL=1024](https://daniehua-dsr1-fp4-sgl-isl1024osl1024.hf.space)
  - [ISL=1024, OSL=8192](https://daniehua-dsr1-fp4-sgl-isl1024osl8192.hf.space)
  - [ISL=8192, OSL=1024](https://daniehua-dsr1-fp4-sgl-isl8192osl1024.hf.space)


**Good luck! ğŸš€**

Remember:
- **Use submit mode directly**: All-in-one, view ranking real-time â­
- **Performance matters, accuracy matters more!** All optimizations must pass accuracy validation
- **Rapid iteration**: Submit immediately after each optimization, see effects instantly


